# Batch normalizationï¼ˆæ‰¹å½’ä¸€åŒ–ï¼‰

Class: interview
Created: July 14, 2022 3:31 PM
Reviewed: No

## BNçš„æ¦‚å¿µå’Œä½œç”¨

åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€èˆ¬éƒ½ä¼šè¦æ±‚æ¨¡å‹çš„è¾“å…¥åˆ†å¸ƒæ˜¯ç¨³å®šçš„ï¼Œå¦‚æœä¸ç¨³å®šæˆ–è€…è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å¸ƒä¸ä¸€è‡´ï¼Œå°±æˆä¸º**åå˜é‡åç§»**

åœ¨ä¸€ä¸ªå¤æ‚çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­ï¼Œä¹Ÿä¼šè¦æ±‚å…¶ä¸­å„ä¸ªå­éƒ¨åˆ†çš„è¾“å…¥åˆ†å¸ƒæ˜¯ç¨³å®šçš„ï¼Œä¾‹å¦‚æ·±åº¦ç¥ç»ç½‘ç»œï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€å±‚çš„å‚æ•°éƒ½ä¸å…¶ä¹‹å‰çš„å±‚æœ‰å…³ç³»ï¼Œå½“ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°æ—¶ï¼Œå½“ä¹‹å‰å±‚çš„å‚æ•°è¢«æ›´æ–°ï¼Œåä¸€å±‚è¾“å…¥æ•°æ®çš„åˆ†å¸ƒä¹Ÿä¼šè·Ÿç€å˜åŒ–ï¼Œå°±ä¸º**å†…éƒ¨åå˜é‡åç§»**

ç½‘ç»œè¶Šæ·±ï¼Œå†…éƒ¨åå˜é‡åç§»ä¼šç»™è®­ç»ƒå¸¦æ¥è®¸å¤šé—®é¢˜ï¼š

<aside>
ğŸ’¡ ç½‘ç»œæ¯ä¸€å±‚è®­ç»ƒæ›´æ–°å‚æ•°æ—¶éƒ½éœ€è¦ä¸æ–­é€‚åº”è¾“å…¥æ•°æ®çš„åˆ†å¸ƒçš„å˜åŒ–ï¼Œå½±å“è®­ç»ƒæ•ˆç‡ï¼Œå¹¶ä¸”ä½¿å¾—å­¦ä¹ è¿‡ç¨‹å˜å¾—ä¸ç¨³å®š

</aside>

<aside>
ğŸ’¡ ä¸ºäº†å°½é‡é™ä½å†…éƒ¨åå˜é‡åç§»çš„å½±å“ï¼Œç½‘ç»œå‚æ•°çš„æ›´æ–°éœ€è¦æ›´åŠ è°¨æ…ï¼Œä½¿å¾—ä¸€èˆ¬é‡‡ç”¨è¾ƒå°çš„å­¦ä¹ ç‡

</aside>

æ‰¹å½’ä¸€åŒ–å°±æ˜¯ä¸ºäº†è§£å†³å†…éƒ¨åå˜é‡åç§»çš„é—®é¢˜è€Œæå‡ºçš„ï¼Œä¸»è¦ä½œç”¨æ˜¯ä½¿å¾—æ¯ä¸€å±‚çš„å‚æ•°å‘ç”Ÿäº†å˜åŒ–ï¼Œè¾“å…¥è¾“å‡ºæ•°æ®çš„åˆ†å¸ƒä¹Ÿä¸ä¼šäº§ç”Ÿè¾ƒå¤§å˜åŒ–ï¼Œ**ä½¿å¾—è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œé¿å…äº†æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±ï¼Œå¯ä»¥åŠ å¿«æ¨¡å‹è®­ç»ƒæ—¶çš„æ”¶æ•›é€Ÿåº¦**

æ‰¹å½’ä¸€åŒ–çš„æ ¸å¿ƒå…¬å¼ï¼š

![Untitled](https://github.com/Sunnyio8/Machine-learning-studies/blob/main/images/Untitled.png)

## ****BNä¸­å‡å€¼ã€æ–¹å·®é€šè¿‡å“ªäº›ç»´åº¦è®¡ç®—å¾—åˆ°ï¼Ÿ****

ç¥ç»ç½‘ç»œä¸­ä¼ é€’çš„å¼ é‡æ•°æ®ï¼Œå…¶ç»´åº¦é€šå¸¸è®°ä¸º[N, H, W, C]ï¼Œå…¶ä¸­Næ˜¯batch_sizeï¼ŒHã€Wæ˜¯è¡Œã€åˆ—ï¼ŒCæ˜¯é€šé“æ•°ã€‚é‚£ä¹ˆä¸Šå¼ä¸­BNçš„è¾“å…¥é›†åˆå°±æ˜¯ä¸‹å›¾ä¸­è“è‰²çš„éƒ¨åˆ†ã€‚

![Untitled](Batch%20normalization%EF%BC%88%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%89%20704cf48e4f6a472d90abca45b157413e/Untitled%201.png)

å‡å€¼çš„è®¡ç®—ï¼Œå°±æ˜¯åœ¨ä¸€ä¸ªæ‰¹æ¬¡å†…ï¼Œå°†æ¯ä¸ªé€šé“ä¸­çš„æ•°å­—å•ç‹¬åŠ èµ·æ¥ï¼Œå†é™¤ä»¥NÃ—HÃ—Wã€‚å¯è®­ç»ƒå‚æ•°çš„ç»´åº¦ç­‰äºå¼ é‡çš„é€šé“æ•°ï¼ŒRGBé€šé“åˆ†åˆ«éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œå› æ­¤ç»´åº¦ç­‰äº3

## ****è®­ç»ƒä¸æ¨ç†æ—¶BNä¸­çš„å‡å€¼ã€æ–¹å·®åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ****

**è®­ç»ƒ**æ—¶ï¼Œå‡å€¼ã€æ–¹å·®åˆ†åˆ«æ˜¯**è¯¥æ‰¹æ¬¡**å†…æ•°æ®ç›¸åº”ç»´åº¦çš„å‡å€¼ä¸æ–¹å·®ï¼›

**æ¨ç†**æ—¶ï¼Œå‡å€¼ã€æ–¹å·®æ˜¯**åŸºäºæ‰€æœ‰æ‰¹æ¬¡**çš„æœŸæœ›è®¡ç®—æ‰€å¾—

BNå±‚åœ¨â€è®­ç»ƒæ¨¡å¼â€œï¼ˆé€šè¿‡å°æ‰¹é‡ç»Ÿè®¡æ•°æ®è§„èŒƒåŒ–ï¼‰å’Œâ€œé¢„æµ‹æ¨¡å¼â€ï¼ˆé€šè¿‡æ•°æ®é›†ç»Ÿè®¡è§„èŒƒåŒ–ï¼‰ä¸­çš„åŠŸèƒ½ä¸åŒã€‚ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ— æ³•å¾—çŸ¥ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†æ¥ä¼°è®¡å¹³å‡å€¼å’Œæ–¹å·®ï¼Œæ‰€ä»¥åªèƒ½æ ¹æ®æ¯ä¸ªå°æ‰¹æ¬¡çš„å¹³å‡å€¼å’Œæ–¹å·®ä¸æ–­è®­ç»ƒæ¨¡å‹ã€‚ è€Œåœ¨é¢„æµ‹æ¨¡å¼ä¸‹ï¼Œå¯ä»¥æ ¹æ®æ•´ä¸ªæ•°æ®é›†ç²¾ç¡®è®¡ç®—æ‰¹é‡è§„èŒƒåŒ–æ‰€éœ€çš„å¹³å‡å€¼å’Œæ–¹å·®ã€‚

 

### **æ³¨æ„ï¼šå½“batch sizeè¶Šå°ï¼ŒBNçš„è¡¨ç°æ•ˆæœä¹Ÿè¶Šä¸å¥½ï¼Œå› ä¸ºè®¡ç®—è¿‡ç¨‹ä¸­æ‰€å¾—åˆ°çš„å‡å€¼å’Œæ–¹å·®ä¸èƒ½ä»£è¡¨å…¨å±€**

## BNå±‚çš„ä»é›¶å®ç°ï¼š

```python
def batch_norm(input_data, gamma, beta, moving_mean, moving_var, eps, momentum):
    if not torch.is_grad_enabled():
        X_hat = (input_data - moving_mean)/torch.sqrt(moving_var - eps)
    else:
        assert len(input_data.shape) == (2, 4)
        if len(input_adta.shape) == 2:
        #å…¨è¿æ¥å±‚
            mean = input_data.mean(dim=0)
            var = ((input_data - mean)**2).mean(dim=0)
        else:
            mean = input_data.mean(dim=0, keep_dim=True).mean(dim=2, keep_dim=True).mean(dim=3, keep_dim=True)
            var = ((input_data - mean)**2).mean(dim=0, keep_dim=True).mean(dim=2, keep_dim=True).mean(dim=3, keep_dim=True)
        X_hat = (input_data - mean)/torch.sqrt(var - eps)
        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
        moving_var = momentum * moving_var + (1.0 - momentum) * var
    Y = gamma*X_hat + beta
    return Y, moving_mean, moving_var

class batchNorm(nn.Module):
    def __init__ (self, num_features, num_dims):
        super(batchNorm, self) __init__()
        if num_dims == 2:
            shape = (1, num_features)
        else:
            shape = (1, num_features, 1, 1)
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)
    def forward(self, x):
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)
        Y, self.moving_mean, self.moving_var = batch_norm(x, self.gamma, self.beta, self.moving_mean, self.moving_var, 1e-5, 0.9)
        return Y
```
